{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(start_time, init_time):\n",
    "    # Calculate the difference in time\n",
    "    diff = start_time - init_time\n",
    "\n",
    "    # Get the total number of seconds\n",
    "    total_seconds = diff.total_seconds()\n",
    "\n",
    "    # Calculate hours, minutes, and seconds\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    # Calculate milliseconds\n",
    "    milliseconds = int((seconds % 1) * 1000)\n",
    "\n",
    "    # Format the time\n",
    "    time_str = \"{:02}:{:02}:{:02},{:03}\".format(int(hours), int(minutes), int(seconds), milliseconds)\n",
    "\n",
    "    return time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_sentence(sentence, max_chars):\n",
    "    # Split the sentence into individual Chinese characters\n",
    "    chars = list(sentence)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sentences = []\n",
    "    current_sentence = \"\"\n",
    "    current_chars = 0\n",
    "    \n",
    "    # Iterate through each character\n",
    "    for char in chars:\n",
    "        # Check if adding the current character exceeds the maximum character limit\n",
    "        if current_chars + len(char) > max_chars:\n",
    "            # Add the current sentence to the list of sentences\n",
    "            sentences.append(current_sentence)\n",
    "            \n",
    "            # Reset the current sentence and character count\n",
    "            current_sentence = \"\"\n",
    "            current_chars = 0\n",
    "        \n",
    "        # Add the current character to the current sentence\n",
    "        current_sentence += char\n",
    "        current_chars += len(char)\n",
    "    \n",
    "    # Add the last sentence to the list of sentences\n",
    "    sentences.append(current_sentence)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_srt_file(ref_wav_path, prompt_text, prompt_language, text, text_language,srt_file_path,srt_gen=True,\n",
    "                 how_to_cut=i18n(\"按标点符号切\"), top_k=20, top_p=0.6, temperature=0.6, ref_free = False):\n",
    "    if prompt_text is None or len(prompt_text) == 0:\n",
    "        ref_free = True\n",
    "    t0 = ttime()\n",
    "    prompt_language = dict_language[prompt_language]\n",
    "    text_language = dict_language[text_language]\n",
    "    if not ref_free:\n",
    "        prompt_text = prompt_text.strip(\"\\n\")\n",
    "        if (prompt_text[-1] not in splits): prompt_text += \"。\" if prompt_language != \"en\" else \".\"\n",
    "        print(i18n(\"实际输入的参考文本:\"), prompt_text)\n",
    "    text = text.strip(\"\\n\")\n",
    "    if (text[0] not in splits and len(get_first(text)) < 4): text = \"。\" + text if text_language != \"en\" else \".\" + text\n",
    "    \n",
    "    print(i18n(\"实际输入的目标文本:\"), text)\n",
    "    zero_wav = np.zeros(\n",
    "        int(hps.data.sampling_rate * 0.3),\n",
    "        dtype=np.float16 if is_half == True else np.float32,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        wav16k, sr = librosa.load(ref_wav_path, sr=16000)\n",
    "        if (wav16k.shape[0] > 160000 or wav16k.shape[0] < 48000):\n",
    "            raise OSError(i18n(\"参考音频在3~10秒范围外，请更换！\"))\n",
    "        wav16k = torch.from_numpy(wav16k)\n",
    "        zero_wav_torch = torch.from_numpy(zero_wav)\n",
    "        if is_half == True:\n",
    "            wav16k = wav16k.half().to(device)\n",
    "            zero_wav_torch = zero_wav_torch.half().to(device)\n",
    "        else:\n",
    "            wav16k = wav16k.to(device)\n",
    "            zero_wav_torch = zero_wav_torch.to(device)\n",
    "        wav16k = torch.cat([wav16k, zero_wav_torch])\n",
    "        ssl_content = ssl_model.model(wav16k.unsqueeze(0))[\n",
    "            \"last_hidden_state\"\n",
    "        ].transpose(\n",
    "            1, 2\n",
    "        )  # .float()\n",
    "        codes = vq_model.extract_latent(ssl_content)\n",
    "   \n",
    "        prompt_semantic = codes[0, 0]\n",
    "    t1 = ttime()\n",
    "\n",
    "    if (how_to_cut == i18n(\"凑四句一切\")):\n",
    "        text = cut1(text)\n",
    "    elif (how_to_cut == i18n(\"凑50字一切\")):\n",
    "        text = cut2(text)\n",
    "    elif (how_to_cut == i18n(\"按中文句号。切\")):\n",
    "        text = cut3(text)\n",
    "    elif (how_to_cut == i18n(\"按英文句号.切\")):\n",
    "        text = cut4(text)\n",
    "    elif (how_to_cut == i18n(\"按标点符号切\")):\n",
    "        text = cut5(text)\n",
    "    while \"\\n\\n\" in text:\n",
    "        text = text.replace(\"\\n\\n\", \"\\n\")\n",
    "    print(i18n(\"实际输入的目标文本(切句后):\"), text)\n",
    "    texts = text.split(\"\\n\")\n",
    "    texts = merge_short_text_in_array(texts, 5)\n",
    "    audio_opt = []\n",
    "    if not ref_free:\n",
    "        phones1,bert1,norm_text1=get_phones_and_bert(prompt_text, prompt_language)\n",
    "    srt_entries = []\n",
    "    \n",
    "    for text in texts:\n",
    "        # 解决输入目标文本的空行导致报错的问题\n",
    "        if (len(text.strip()) == 0):\n",
    "            continue\n",
    "        if (text[-1] not in splits): text += \"。\" if text_language != \"en\" else \".\"\n",
    "        print(i18n(\"实际输入的目标文本(每句):\"), text)\n",
    "        phones2,bert2,norm_text2=get_phones_and_bert(text, text_language)\n",
    "        print(i18n(\"前端处理后的文本(每句):\"), norm_text2)\n",
    "        if not ref_free:\n",
    "            bert = torch.cat([bert1, bert2], 1)\n",
    "            all_phoneme_ids = torch.LongTensor(phones1+phones2).to(device).unsqueeze(0)\n",
    "        else:\n",
    "            bert = bert2\n",
    "            all_phoneme_ids = torch.LongTensor(phones2).to(device).unsqueeze(0)\n",
    "\n",
    "        bert = bert.to(device).unsqueeze(0)\n",
    "        all_phoneme_len = torch.tensor([all_phoneme_ids.shape[-1]]).to(device)\n",
    "        prompt = prompt_semantic.unsqueeze(0).to(device)\n",
    "        t2 = ttime()\n",
    "        with torch.no_grad():\n",
    "            # pred_semantic = t2s_model.model.infer(\n",
    "            pred_semantic, idx = t2s_model.model.infer_panel(\n",
    "                all_phoneme_ids,\n",
    "                all_phoneme_len,\n",
    "                None if ref_free else prompt,\n",
    "                bert,\n",
    "                # prompt_phone_len=ph_offset,\n",
    "                top_k=top_k,\n",
    "                top_p=top_p,\n",
    "                temperature=temperature,\n",
    "                early_stop_num=hz * max_sec,\n",
    "            )\n",
    "        t3 = ttime()\n",
    "        # print(pred_semantic.shape,idx)\n",
    "        pred_semantic = pred_semantic[:, -idx:].unsqueeze(\n",
    "            0\n",
    "        )  # .unsqueeze(0)#mq要多unsqueeze一次\n",
    "        refer = get_spepc(hps, ref_wav_path)  # .to(device)\n",
    "        if is_half == True:\n",
    "            refer = refer.half().to(device)\n",
    "        else:\n",
    "            refer = refer.to(device)\n",
    "        # audio = vq_model.decode(pred_semantic, all_phoneme_ids, refer).detach().cpu().numpy()[0, 0]\n",
    "        audio = (\n",
    "            vq_model.decode(\n",
    "                pred_semantic, torch.LongTensor(phones2).to(device).unsqueeze(0), refer\n",
    "            )\n",
    "                .detach()\n",
    "                .cpu()\n",
    "                .numpy()[0, 0]\n",
    "        )  ###试试重建不带上prompt部分\n",
    "        ### ——————————————生成字幕————————————————————————\n",
    "        audio_duration = len(audio) / hps.data.sampling_rate\n",
    "        text = text.replace('。','').replace(',','')\n",
    "        if len(srt_entries) == 0:\n",
    "            init_time = datetime.datetime.now()\n",
    "            start_time = init_time+datetime.timedelta(seconds=0)\n",
    "        cut_sub_list = cut_sentence(text,8)\n",
    "        if len(cut_sub_list)>1:\n",
    "            audio_piece = audio_duration/len(cut_sub_list)\n",
    "            for sub in cut_sub_list:\n",
    "                end_time = start_time+datetime.timedelta(seconds=audio_piece)\n",
    "                srt_entry = f\"{len(srt_entries) + 1}\\n{format_time(start_time,init_time)} --> {format_time(end_time,init_time)}\\n{sub}\\n\\n\"\n",
    "                start_time = end_time\n",
    "                #print(srt_entry)\n",
    "                srt_entries.append(srt_entry)\n",
    "        else:\n",
    "            end_time = start_time+datetime.timedelta(seconds=audio_duration)\n",
    "            srt_entry = f\"{len(srt_entries) + 1}\\n{format_time(start_time,init_time)} --> {format_time(end_time,init_time)}\\n{text}\\n\\n\"\n",
    "            start_time = end_time\n",
    "            #print(srt_entry)\n",
    "            srt_entries.append(srt_entry)\n",
    "        ### ————————————————生成字幕结束——————————————————————\n",
    "        t4 = ttime()\n",
    "    print(\"%.3f\\t%.3f\\t%.3f\\t%.3f\" % (t1 - t0, t2 - t1, t3 - t2, t4 - t3))\n",
    "    if srt_gen:\n",
    "        with open(srt_file_path, \"w\",encoding='utf-8') as srt_file:\n",
    "            srt_file.writelines(srt_entries)\n",
    "            print('srt generated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess,time\n",
    "st=time.time()\n",
    "proc = subprocess.Popen(['ffmpeg','-y','-i','xuniren/final/保单分析帮你分析保险回本能力.mp4','-vf','subtitles=temp/subtitle.srt','temp/sub_video.mp4'])\n",
    "proc.wait()\n",
    "print(f'run time:{time.time()-st}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ": TextClip(txt, font='Alibaba-PuHuiTi-2-85-Bold', font_size=75, color='white',method='caption',align='center',size=(900,1920),kerning=3,stroke_color='black',stroke_width=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
